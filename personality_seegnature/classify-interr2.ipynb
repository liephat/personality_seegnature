{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method for grid search with different classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_logistic_regression(X, y):\n",
    "    # Grid search with logistic regression\n",
    "    lr = LogisticRegression(C=1.0)\n",
    "\n",
    "    # GridSearch for liblinear solver\n",
    "    C_range = [0.1, 1, 10, 100, 1000, 10000]\n",
    "    penalty_options = ['l1', 'l2']\n",
    "    fit_intercept_options = [True, False]\n",
    "    solver_option = ['liblinear']\n",
    "    class_weight_option = ['auto', '']\n",
    "\n",
    "    param_grid = dict(C=C_range, penalty=penalty_options, fit_intercept=fit_intercept_options, solver=solver_option)\n",
    "\n",
    "    # solver_options = ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "    # multi_class_options = ['ovr', 'multinomial']\n",
    "    # class_weight_options = [None, 'balanced']\n",
    "\n",
    "    # param_grid = dict(solver = solver_options, multi_class = multi_class_options, class_weight = class_weight_options)\n",
    "\n",
    "    perform_grid_search(lr, X, y, param_grid, \"Logistic Regression\")\n",
    "    \n",
    "    # tune_parameters_for_scores(lr, X, y, param_grid, ['precision', 'recall'])\n",
    "\n",
    "\n",
    "def perform_lda(X, y):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    solver_options = ['lsqr']\n",
    "    #shrinkage_options = [None, 'auto']\n",
    "    shrinkage = np.arange(0.0, 1.05, 0.05)\n",
    "    \n",
    "    param_grid = dict(solver=solver_options, shrinkage=shrinkage)\n",
    "\n",
    "    perform_grid_search(lda, X, y, param_grid, \"LDA\")\n",
    "    \n",
    "    # for iteration in range(0, 10):\n",
    "    #    tune_parameters_for_scores(lda, X, y, param_grid, ['accuracy'], iteration)\n",
    "    \n",
    "\n",
    "def perform_svc(X, y):\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    \n",
    "    for iteration in range(0, 10):\n",
    "        tune_parameters_for_scores(SVC(), X, y, tuned_parameters, ['accuracy'], iteration)\n",
    "\n",
    "    \n",
    "def perform_grid_search(clf, X, y, param_grid, name):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    grid_clf = GridSearchCV(clf, param_grid, cv=cv, scoring='accuracy')\n",
    "    grid_clf.fit(X, y)\n",
    "\n",
    "    print(\"# Tuning parameters for %s\" % name)\n",
    "    print()\n",
    "    # best results\n",
    "    print(\"The best parameters are %s with a score of %0.2f\" \\\n",
    "          % (grid_clf.best_params_, grid_clf.best_score_))\n",
    "    print()\n",
    "    # complete results\n",
    "    means = grid_clf.cv_results_['mean_test_score']\n",
    "    stds = grid_clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid_clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_parameters_for_scores(method, X, y, param_grid, scores, random_state, print_grid_scores=False, test_size=False) :\n",
    "    # Split the dataset in two equal parts\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=random_state)\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(method, param_grid, cv=cv,\n",
    "                           scoring='%s' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        \n",
    "        if print_grid_scores:\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std, params))\n",
    "            print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHANNELS = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FCz', 'FC6', 'T7', 'C3', 'Cz', 'C4',\n",
    "            'T8', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'O2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set important directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_directory = 'L:/int_err2'\n",
    "current_path = os.path.abspath(working_directory)\n",
    "image_directory = os.path.abspath(os.path.join(current_path, 'images'))\n",
    "pickle_directory = os.path.abspath(os.path.join(current_path, 'pickles'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load separability indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_comp_corr_file = os.path.abspath(os.path.join(pickle_directory, 'std_comp_corr.pkl'))\n",
    "with open(std_comp_corr_file, 'rb') as pickle_file:\n",
    "    std_comp_corr = pickle.load(pickle_file)\n",
    "    \n",
    "std_incomp_corr_file = os.path.abspath(os.path.join(pickle_directory, 'std_incomp_corr.pkl'))\n",
    "with open(std_incomp_corr_file, 'rb') as pickle_file:\n",
    "    std_incomp_corr = pickle.load(pickle_file)\n",
    "    \n",
    "ts_comp_corr_file = os.path.abspath(os.path.join(pickle_directory, 'ts_comp_corr.pkl'))\n",
    "with open(ts_comp_corr_file, 'rb') as pickle_file:\n",
    "    ts_comp_corr = pickle.load(pickle_file)\n",
    "    \n",
    "ts_incomp_corr_file = os.path.abspath(os.path.join(pickle_directory, 'ts_incomp_corr.pkl'))\n",
    "with open(ts_incomp_corr_file, 'rb') as pickle_file:\n",
    "    ts_incomp_corr = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_comp_corr.extract_features([[112, 160]], CHANNELS, 'Consc_Group')\n",
    "std_incomp_corr.extract_features([[-60, -40], [112, 148]], CHANNELS, 'Consc_Group')\n",
    "ts_comp_corr.extract_features([[112, 152], [468, 484]], CHANNELS, 'Consc_Group')\n",
    "ts_incomp_corr.extract_features([[-20, 0], [348, 380]], CHANNELS, 'Consc_Group')\n",
    "\n",
    "X_std_comp, y_std_comp = std_comp_corr.get_features_and_labels('Consc_Group')\n",
    "X_std_incomp, y_std_incomp = std_incomp_corr.get_features_and_labels('Consc_Group')\n",
    "X_ts_comp, y_ts_comp = std_comp_corr.get_features_and_labels('Consc_Group')\n",
    "X_ts_incomp, y_ts_incomp = std_incomp_corr.get_features_and_labels('Consc_Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning parameters for LDA\n",
      "\n",
      "The best parameters are {'shrinkage': 0.4, 'solver': 'lsqr'} with a score of 0.69\n",
      "\n",
      "0.519 (+/-0.225) for {'shrinkage': 0.0, 'solver': 'lsqr'}\n",
      "0.611 (+/-0.277) for {'shrinkage': 0.05, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.296) for {'shrinkage': 0.1, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.15000000000000002, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.2, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.25, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.30000000000000004, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.35000000000000003, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.4, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.45, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.5, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.380) for {'shrinkage': 0.55, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.380) for {'shrinkage': 0.6000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.65, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.7000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.75, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.8, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.432) for {'shrinkage': 0.9, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.439) for {'shrinkage': 0.9500000000000001, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.599) for {'shrinkage': 1.0, 'solver': 'lsqr'}\n",
      "\n",
      "\n",
      "# Tuning parameters for LDA\n",
      "\n",
      "The best parameters are {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'} with a score of 0.69\n",
      "\n",
      "0.500 (+/-0.474) for {'shrinkage': 0.0, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.204) for {'shrinkage': 0.05, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.324) for {'shrinkage': 0.1, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.377) for {'shrinkage': 0.15000000000000002, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.377) for {'shrinkage': 0.2, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.418) for {'shrinkage': 0.25, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.418) for {'shrinkage': 0.30000000000000004, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.35000000000000003, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.4, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.45, 'solver': 'lsqr'}\n",
      "0.574 (+/-0.398) for {'shrinkage': 0.5, 'solver': 'lsqr'}\n",
      "0.574 (+/-0.398) for {'shrinkage': 0.55, 'solver': 'lsqr'}\n",
      "0.611 (+/-0.425) for {'shrinkage': 0.6000000000000001, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.364) for {'shrinkage': 0.65, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.364) for {'shrinkage': 0.7000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.388) for {'shrinkage': 0.75, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.404) for {'shrinkage': 0.8, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.370) for {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.446) for {'shrinkage': 0.9, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.396) for {'shrinkage': 0.9500000000000001, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.374) for {'shrinkage': 1.0, 'solver': 'lsqr'}\n",
      "\n",
      "\n",
      "# Tuning parameters for Logistic Regression\n",
      "\n",
      "The best parameters are {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'} with a score of 0.67\n",
      "\n",
      "0.667 (+/-0.471) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.630 (+/-0.267) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.667 (+/-0.471) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.630 (+/-0.267) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.324) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.369) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.232) for {'C': 100, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.360) for {'C': 100, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.253) for {'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 100, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.326) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.326) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.232) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.253) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.377) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "\n",
      "# Tuning parameters for Logistic Regression\n",
      "\n",
      "The best parameters are {'C': 1000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'} with a score of 0.61\n",
      "\n",
      "0.556 (+/-0.365) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.371) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.365) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.371) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.392) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.274) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.355) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.274) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.477) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.416) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.477) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.593 (+/-0.445) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.482) for {'C': 100, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 100, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.502) for {'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 100, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.454) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.611 (+/-0.433) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.593 (+/-0.337) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.388) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_lda(X_std_comp, y_std_comp)\n",
    "perform_logistic_regression(X_std_comp, y_std_comp)\n",
    "\n",
    "perform_lda(X_std_incomp, y_std_incomp)\n",
    "perform_logistic_regression(X_std_incomp, y_std_incomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning parameters for LDA\n",
      "\n",
      "The best parameters are {'shrinkage': 0.4, 'solver': 'lsqr'} with a score of 0.69\n",
      "\n",
      "0.519 (+/-0.225) for {'shrinkage': 0.0, 'solver': 'lsqr'}\n",
      "0.611 (+/-0.277) for {'shrinkage': 0.05, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.296) for {'shrinkage': 0.1, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.15000000000000002, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.2, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.25, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.30000000000000004, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.318) for {'shrinkage': 0.35000000000000003, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.4, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.45, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.335) for {'shrinkage': 0.5, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.380) for {'shrinkage': 0.55, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.380) for {'shrinkage': 0.6000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.65, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.7000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.75, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.8, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.447) for {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.432) for {'shrinkage': 0.9, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.439) for {'shrinkage': 0.9500000000000001, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.599) for {'shrinkage': 1.0, 'solver': 'lsqr'}\n",
      "\n",
      "\n",
      "# Tuning parameters for Logistic Regression\n",
      "\n",
      "The best parameters are {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'} with a score of 0.67\n",
      "\n",
      "0.667 (+/-0.471) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.630 (+/-0.267) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.667 (+/-0.471) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.630 (+/-0.267) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.242) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.324) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.369) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.265) for {'C': 100, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.360) for {'C': 100, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.274) for {'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.304) for {'C': 100, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.326) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.326) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.232) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.296) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.500 (+/-0.326) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.377) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "\n",
      "# Tuning parameters for LDA\n",
      "\n",
      "The best parameters are {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'} with a score of 0.69\n",
      "\n",
      "0.500 (+/-0.474) for {'shrinkage': 0.0, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.204) for {'shrinkage': 0.05, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.324) for {'shrinkage': 0.1, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.377) for {'shrinkage': 0.15000000000000002, 'solver': 'lsqr'}\n",
      "0.519 (+/-0.377) for {'shrinkage': 0.2, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.418) for {'shrinkage': 0.25, 'solver': 'lsqr'}\n",
      "0.537 (+/-0.418) for {'shrinkage': 0.30000000000000004, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.35000000000000003, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.4, 'solver': 'lsqr'}\n",
      "0.556 (+/-0.410) for {'shrinkage': 0.45, 'solver': 'lsqr'}\n",
      "0.574 (+/-0.398) for {'shrinkage': 0.5, 'solver': 'lsqr'}\n",
      "0.574 (+/-0.398) for {'shrinkage': 0.55, 'solver': 'lsqr'}\n",
      "0.611 (+/-0.425) for {'shrinkage': 0.6000000000000001, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.364) for {'shrinkage': 0.65, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.364) for {'shrinkage': 0.7000000000000001, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.388) for {'shrinkage': 0.75, 'solver': 'lsqr'}\n",
      "0.667 (+/-0.404) for {'shrinkage': 0.8, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.370) for {'shrinkage': 0.8500000000000001, 'solver': 'lsqr'}\n",
      "0.685 (+/-0.446) for {'shrinkage': 0.9, 'solver': 'lsqr'}\n",
      "0.648 (+/-0.396) for {'shrinkage': 0.9500000000000001, 'solver': 'lsqr'}\n",
      "0.630 (+/-0.374) for {'shrinkage': 1.0, 'solver': 'lsqr'}\n",
      "\n",
      "\n",
      "# Tuning parameters for Logistic Regression\n",
      "\n",
      "The best parameters are {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'} with a score of 0.59\n",
      "\n",
      "0.556 (+/-0.365) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.371) for {'C': 0.1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.365) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.371) for {'C': 0.1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.392) for {'C': 1, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.274) for {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.355) for {'C': 1, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.519 (+/-0.274) for {'C': 1, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.477) for {'C': 10, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.416) for {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.477) for {'C': 10, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.593 (+/-0.445) for {'C': 10, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.556 (+/-0.482) for {'C': 100, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 100, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.502) for {'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 100, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.395) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 1000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.524) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 1000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.311) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 10000, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.574 (+/-0.388) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.449) for {'C': 10000, 'fit_intercept': False, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_lda(X_ts_comp, y_ts_comp)\n",
    "perform_logistic_regression(X_ts_comp, y_ts_comp)\n",
    "\n",
    "perform_lda(X_ts_incomp, y_ts_incomp)\n",
    "perform_logistic_regression(X_ts_incomp, y_ts_incomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_evaluation(clf, X, y, n_splits, score='accuracy'):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for iteration in range(0, 10):\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=iteration)\n",
    "\n",
    "        # Variable for accuracy score\n",
    "        mean_score = 0\n",
    "        \n",
    "        for train, test in cv.split(X, y):\n",
    "            \n",
    "            # Compute accuracy score\n",
    "            y_pred = clf.fit(X[train], y[train]).predict(X[test])\n",
    "            \n",
    "            if score is 'accuracy':\n",
    "                mean_score += accuracy_score(y[test], y_pred)\n",
    "            elif score is 'precision':\n",
    "                mean_score += precision_score(y[test], y_pred, pos_label=0)\n",
    "            elif score is 'recall':\n",
    "                mean_score += recall_score(y[test], y_pred, pos_label=0)\n",
    "\n",
    "        # Mean accuracy\n",
    "        mean_score /= n_splits\n",
    "        \n",
    "        results.append(mean_score)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_set_of_evaluations(n_splits, score):\n",
    "    ### Evaluation of classification with STD comp\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.4)\n",
    "    lr = LogisticRegression(C=0.1, fit_intercept=True, penalty='l1', solver='liblinear')\n",
    "\n",
    "    results_lda = run_evaluation(lda, X_std_comp, y_std_comp, n_splits, score)\n",
    "    results_lr = run_evaluation(lr, X_std_comp, y_std_comp, n_splits, score)\n",
    "\n",
    "    results_std_comp = []\n",
    "    results_std_comp.append(results_lda)\n",
    "    results_std_comp.append(results_lr)\n",
    "\n",
    "    ### Evaluation of classification with STD incomp\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.85)\n",
    "    lr = LogisticRegression(C=1000, fit_intercept=False, penalty='l1', solver='liblinear')\n",
    "\n",
    "    results_lda = run_evaluation(lda, X_std_incomp, y_std_incomp, n_splits, score)\n",
    "    results_lr = run_evaluation(lr, X_std_incomp, y_std_incomp, n_splits, score)\n",
    "\n",
    "    results_std_incomp = []\n",
    "    results_std_incomp.append(results_lda)\n",
    "    results_std_incomp.append(results_lr)\n",
    "\n",
    "    ### Evaluation of classification with TS comp\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.4)\n",
    "    lr = LogisticRegression(C=0.1, fit_intercept=True, penalty='l1', solver='liblinear')\n",
    "\n",
    "    results_lda = run_evaluation(lda, X_ts_comp, y_ts_comp, n_splits, score)\n",
    "    results_lr = run_evaluation(lr, X_ts_comp, y_ts_comp, n_splits, score)\n",
    "\n",
    "    results_ts_comp = []\n",
    "    results_ts_comp.append(results_lda)\n",
    "    results_ts_comp.append(results_lr)\n",
    "    \n",
    "    ### Evaluation of classification with TS incomp\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.85)\n",
    "    lr = LogisticRegression(C=0.1, fit_intercept=True, penalty='l1', solver='liblinear')\n",
    "\n",
    "    results_lda = run_evaluation(lda, X_ts_incomp, y_ts_incomp, n_splits, score)\n",
    "    results_lr = run_evaluation(lr, X_ts_incomp, y_ts_incomp, n_splits, score)\n",
    "\n",
    "    results_ts_incomp = []\n",
    "    results_ts_incomp.append(results_lda)\n",
    "    results_ts_incomp.append(results_lr)\n",
    "    \n",
    "    \n",
    "    # make graphics\n",
    "    results_std_comp = np.array(results_std_comp)\n",
    "    results_std_incomp = np.array(results_std_incomp)\n",
    "    results_ts_comp = np.array(results_ts_comp)\n",
    "    results_ts_incomp = np.array(results_ts_incomp)\n",
    "\n",
    "    results = []\n",
    "    print(np.mean(results_std_comp, axis=1))\n",
    "    print(np.mean(results_std_incomp, axis=1))\n",
    "    print(np.mean(results_ts_comp, axis=1))\n",
    "    print(np.mean(results_ts_incomp, axis=1))\n",
    "\n",
    "    print(np.std(results_std_comp, axis=1))\n",
    "    print(np.std(results_std_incomp, axis=1))\n",
    "    print(np.std(results_ts_comp, axis=1))\n",
    "    print(np.std(results_ts_incomp, axis=1))\n",
    "\n",
    "    results.append(results_std_comp)\n",
    "    results.append(results_std_incomp)\n",
    "    results.append(results_ts_comp)\n",
    "    results.append(results_ts_incomp)\n",
    "\n",
    "    results = np.array(results)\n",
    "\n",
    "    means = np.mean(results, axis=2)\n",
    "    stds = np.std(results, axis=2)\n",
    "\n",
    "    print(means.shape)\n",
    "\n",
    "    ind = np.arange(len(means))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind - width/2, means[:,0], width, yerr=stds[:,0], color='SkyBlue', label='LDA', capsize=5)\n",
    "    rects2 = ax.bar(ind + width/2, means[:,1], width, yerr=stds[:,1], color='IndianRed', label='LR', capsize=5)\n",
    "\n",
    "    ax.set_ylabel(score)\n",
    "    ax.set_title('%s by instruction condition and classifier' % score)\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(('STD comp', 'STD incomp', 'TS comp', 'TS incomp'))\n",
    "    ax.legend()\n",
    "\n",
    "    plot_path = os.path.abspath(os.path.join(image_directory, 'interr2_comparison_lr_lda.png'))\n",
    "\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\AppData\\Local\\conda\\conda\\envs\\seegnature\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64266667 0.6       ]\n",
      "[0.59233333 0.45933333]\n",
      "[0.64266667 0.6       ]\n",
      "[0.59233333 0.35      ]\n",
      "[0.05094223 0.08724168]\n",
      "[0.06762725 0.04579665]\n",
      "[0.05094223 0.08724168]\n",
      "[0.06762725 0.06540472]\n",
      "(4, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_set_of_evaluations(10, 'precision')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seegnature",
   "language": "python",
   "name": "seegnature"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
